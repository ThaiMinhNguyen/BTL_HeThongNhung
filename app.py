import streamlit as st
import cv2
import numpy as np
import os
import time
from PIL import Image
import tempfile
import torch
import sys
import yaml
from pathlib import Path

# C√†i ƒë·∫∑t trang
st.set_page_config(
    page_title="Drowning Detection System",
    page_icon="üèä‚Äç‚ôÇÔ∏è",
    layout="wide"
)

# ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng ƒë·ªÉ t·∫Øt weights_only
os.environ["TORCH_WEIGHTS_ONLY"] = "0"

# Ki·ªÉm tra v√† c√†i ƒë·∫∑t th∆∞ vi·ªán
try:
    import ultralytics
    from ultralytics import YOLO
except ImportError:
    st.error("Ultralytics kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t. ƒêang c√†i ƒë·∫∑t...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "ultralytics"])
    import ultralytics
    from ultralytics import YOLO

# Th√™m c√°c module c·∫ßn thi·∫øt v√†o danh s√°ch an to√†n
try:
    import torch.nn.modules.container
    torch.serialization.add_safe_globals([
        ultralytics.nn.tasks.DetectionModel,
        torch.nn.modules.container.Sequential
    ])
except Exception as e:
    st.warning(f"Kh√¥ng th·ªÉ thi·∫øt l·∫≠p safe_globals: {e}")
    
class DrowningDetectionApp:
    def __init__(self):
        # Available models
        self.models = {
            "Model 1 (best.pt)": "runs/drowning_detection/weights/best.pt",
            "Model 2 (best1.pt)": "runs/drowning_detection/weights/best1.pt",
            "Model 3 (best2.pt)": "runs/drowning_detection/weights/best2.pt", #best model by far
            "Model 4 (blurry.pt)": "runs/drowning_detection/weights/blurry.pt", #blurry model
            "Model 5 (best3.pt)": "runs/drowning_detection/weights/best3.pt",
            "Model 6 (model.pt)": "runs/drowning_detection/weights/model.pt"
        }
        
        # Default values
        self.conf_threshold = 0.25
        self.alert_conf = 0.65
        self.alert_time = 5.0
        self.model = None
        self.temp_dir = "drowning_alerts"
        os.makedirs(self.temp_dir, exist_ok=True)
        
    def load_model(self, model_path):
        """Load the selected YOLO model"""
        try:
            st.write(f"ƒêang t·∫£i model t·ª´: {model_path}")
            
            # Ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i
            if not os.path.exists(model_path):
                st.error(f"File model kh√¥ng t·ªìn t·∫°i: {model_path}")
                # Li·ªát k√™ c√°c file trong th∆∞ m·ª•c
                model_dir = os.path.dirname(model_path)
                if os.path.exists(model_dir):
                    st.write(f"C√°c file c√≥ trong th∆∞ m·ª•c {model_dir}:")
                    for file in os.listdir(model_dir):
                        st.write(f"- {file}")
                return False
            
            # C·ªë g·∫Øng t·∫£i model v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p kh√°c nhau
            try:
                # Ph∆∞∆°ng ph√°p 1: S·ª≠ d·ª•ng context manager
                with torch.serialization.safe_globals([
                    ultralytics.nn.tasks.DetectionModel,
                    torch.nn.modules.container.Sequential
                ]):
                    self.model = YOLO(model_path)
                st.success("T·∫£i model th√†nh c√¥ng (ph∆∞∆°ng ph√°p 1)")
                return True
                
            except Exception as e1:
                st.warning(f"Ph∆∞∆°ng ph√°p 1 th·∫•t b·∫°i: {e1}")
                
                # Ph∆∞∆°ng ph√°p 2: S·ª≠ d·ª•ng monkey patch
                try:
                    # L∆∞u h√†m g·ªëc
                    original_torch_load = torch.load
                    
                    # T·∫°o h√†m patch
                    def patched_torch_load(*args, **kwargs):
                        kwargs['weights_only'] = False
                        return original_torch_load(*args, **kwargs)
                    
                    # √Åp d·ª•ng patch
                    torch.load = patched_torch_load
                    
                    # T·∫£i model
                    self.model = YOLO(model_path)
                    
                    # Kh√¥i ph·ª•c h√†m g·ªëc
                    torch.load = original_torch_load
                    
                    st.success("T·∫£i model th√†nh c√¥ng (ph∆∞∆°ng ph√°p 2)")
                    return True
                    
                except Exception as e2:
                    st.warning(f"Ph∆∞∆°ng ph√°p 2 th·∫•t b·∫°i: {e2}")
                    
                    # Ph∆∞∆°ng ph√°p 3: S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng
                    try:
                        os.environ["TORCH_WEIGHTS_ONLY"] = "0"
                        self.model = YOLO(model_path)
                        st.success("T·∫£i model th√†nh c√¥ng (ph∆∞∆°ng ph√°p 3)")
                        return True
                    except Exception as e3:
                        st.error(f"Ph∆∞∆°ng ph√°p 3 th·∫•t b·∫°i: {e3}")
                        return False
                        
        except Exception as e:
            st.error(f"L·ªói t·∫£i model: {str(e)}")
            return False
    
    def process_video(self, video_file, conf_threshold, alert_conf, alert_time):
        """Process video for drowning detection"""
        if self.model is None:
            st.error("Vui l√≤ng t·∫£i model tr∆∞·ªõc khi x·ª≠ l√Ω video")
            return
        
        # T·∫°o file t·∫°m ƒë·ªÉ l∆∞u video t·∫£i l√™n
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(video_file.read())
        tfile.close()
        
        # M·ªü video
        cap = cv2.VideoCapture(tfile.name)
        if not cap.isOpened():
            st.error("Kh√¥ng th·ªÉ m·ªü file video")
            return
        
        # L·∫•y th√¥ng s·ªë video
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # Bi·∫øn theo d√µi ph√°t hi·ªán ƒëu·ªëi n∆∞·ªõc
        drowning_start_time = None
        current_time = time.time()
        alert_saved = False
        show_alert = False
        frame_count = 0
        
        # T·∫°o c√°c placeholders cho Streamlit
        progress_bar = st.progress(0)
        video_placeholder = st.empty()
        status_placeholder = st.empty()
        info_placeholder = st.empty()
        alert_placeholder = st.empty()
        
        status_placeholder.info("ƒêang x·ª≠ l√Ω video...")
        
        # T·∫°o c·ªôt cho c√°c ch·ªâ s·ªë
        col1, col2, col3 = st.columns(3)
        drowning_metric = col1.empty()
        swimming_metric = col2.empty()
        tread_water_metric = col3.empty()
        
        # Hi·ªÉn th·ªã gi√° tr·ªã ban ƒë·∫ßu
        drowning_metric.metric(label="ƒêu·ªëi n∆∞·ªõc", value=0)
        swimming_metric.metric(label="B∆°i", value=0)
        tread_water_metric.metric(label="V√πng v·∫´y", value=0)
        
        # X·ª≠ l√Ω video
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            progress_value = min(float(frame_count) / total_frames, 1.0)
            progress_bar.progress(progress_value)
            
            # Ch·∫°y ph√°t hi·ªán
            results = self.model(frame, conf=conf_threshold, verbose=False)[0]
            
            # X·ª≠ l√Ω k·∫øt qu·∫£ ph√°t hi·ªán
            boxes = []
            classes = []
            confidences = []
            is_drowning_detected = False
            high_conf_drowning = False
            drowning_count = 0
            swimming_count = 0
            tread_water_count = 0
            max_drowning_conf = 0
            
            for detection in results.boxes.data:
                x1, y1, x2, y2, conf, cls = detection
                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
                
                # L·∫•y t√™n l·ªõp
                class_id = int(cls)
                class_name = self.model.names[class_id]
                
                # Th√™m v√†o danh s√°ch
                boxes.append([x1, y1, x2, y2])
                classes.append(class_name)
                confidences.append(conf.item())
                
                # ƒê·∫øm theo t·ª´ng l·ªõp
                if class_name == "drowning":
                    drowning_count += 1
                    conf_value = conf.item()
                    max_drowning_conf = max(max_drowning_conf, conf_value)
                    if conf_value > alert_conf:
                        is_drowning_detected = True
                        high_conf_drowning = True
                elif class_name == "swimming":
                    swimming_count += 1
                elif class_name == "tread water":
                    tread_water_count += 1
            
            # C·∫≠p nh·∫≠t s·ªë li·ªáu
            drowning_metric.metric(label="ƒêu·ªëi n∆∞·ªõc", value=drowning_count)
            swimming_metric.metric(label="B∆°i", value=swimming_count)
            tread_water_metric.metric(label="V√πng v·∫´y", value=tread_water_count)
            
            # C·∫≠p nh·∫≠t b·ªô ƒë·∫øm th·ªùi gian ƒëu·ªëi n∆∞·ªõc
            if high_conf_drowning:
                if drowning_start_time is None:
                    drowning_start_time = time.time()
                    alert_saved = False
            else:
                drowning_start_time = None
            
            # T√≠nh th·ªùi gian ƒëu·ªëi n∆∞·ªõc
            drowning_duration = 0
            if drowning_start_time is not None:
                drowning_duration = time.time() - drowning_start_time
            
            # X√°c ƒë·ªãnh xem c√≥ n√™n hi·ªÉn th·ªã c·∫£nh b√°o kh√¥ng
            show_alert = drowning_start_time is not None and drowning_duration >= alert_time
            
            # V·∫Ω bounding box v√† c·∫£nh b√°o
            processed_frame = self.draw_bbox(frame, boxes, classes, confidences, show_alert)
            
            # T·ª± ƒë·ªông l∆∞u h√¨nh ·∫£nh khi ph√°t hi·ªán ƒëu·ªëi n∆∞·ªõc
            if show_alert and not alert_saved:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                save_path = os.path.join(self.temp_dir, f"drowning_alert_{timestamp}.jpg")
                cv2.imwrite(save_path, processed_frame)
                alert_saved = True
                status_placeholder.warning(f"C·∫£nh b√°o! ƒê√£ l∆∞u h√¨nh ·∫£nh: {save_path}")
                
                # Hi·ªÉn th·ªã h√¨nh ·∫£nh ƒë√£ l∆∞u
                alert_img = Image.open(save_path)
                alert_placeholder.image(alert_img, caption="‚ö†Ô∏è PH√ÅT HI·ªÜN ƒêU·ªêI N∆Ø·ªöC! ‚ö†Ô∏è", use_column_width=True)
            
            # Th√™m ch·ªâ b√°o b·ªô ƒë·∫øm th·ªùi gian ƒëu·ªëi n∆∞·ªõc
            if drowning_start_time is not None:
                timer_text = f"Th·ªùi gian ƒëu·ªëi n∆∞·ªõc: {drowning_duration:.1f}s / {alert_time:.1f}s"
                cv2.putText(processed_frame, timer_text, (10, 60), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                # Hi·ªÉn th·ªã b·ªô ƒë·∫øm th·ªùi gian trong tr·∫°ng th√°i
                status_placeholder.warning(f"‚ö†Ô∏è C√≥ th·ªÉ ƒëang ƒëu·ªëi n∆∞·ªõc! Th·ªùi gian: {drowning_duration:.1f}s / {alert_time:.1f}s")
            
            # C·∫≠p nh·∫≠t th√¥ng tin
            info_text = f"""
            ## K·∫øt qu·∫£ ph√°t hi·ªán:
            - ƒêu·ªëi n∆∞·ªõc: {drowning_count}
            - B∆°i: {swimming_count}
            - V√πng v·∫´y: {tread_water_count}
            """
            if drowning_count > 0:
                info_text += f"- ƒê·ªô tin c·∫≠y ƒëu·ªëi n∆∞·ªõc cao nh·∫•t: {max_drowning_conf:.2f}\n"
            
            info_placeholder.markdown(info_text)
            
            # Chuy·ªÉn ƒë·ªïi sang RGB ƒë·ªÉ hi·ªÉn th·ªã
            rgb_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
            video_placeholder.image(rgb_frame, caption="ƒêang x·ª≠ l√Ω video", use_column_width=True)
        
        # D·ªçn d·∫πp
        cap.release()
        os.unlink(tfile.name)
        status_placeholder.success("X·ª≠ l√Ω video ho√†n t·∫•t")
    
    def draw_bbox(self, frame, boxes, classes, confidences, is_drowning=False):
        """V·∫Ω bounding box l√™n khung h√¨nh"""
        out = frame.copy()
        
        # M√†u s·∫Øc cho c√°c l·ªõp kh√°c nhau (ƒë·ªãnh d·∫°ng BGR)
        class_colors = {
            "swimming": (0, 255, 0),      # Xanh l√°
            "tread water": (0, 255, 255), # V√†ng
            "drowning": (0, 0, 255)       # ƒê·ªè
        }
        
        # V·∫Ω bounding box
        for i, box in enumerate(boxes):
            x1, y1, x2, y2 = box
            confidence = confidences[i]
            label = classes[i]
            
            # L·∫•y m√†u d·ª±a v√†o l·ªõp
            color = class_colors.get(label, (255, 0, 0))  # M·∫∑c ƒë·ªãnh l√† xanh d∆∞∆°ng
            
            # V·∫Ω box v·ªõi ƒë∆∞·ªùng vi·ªÅn d√†y h∆°n n·∫øu l√† ƒëu·ªëi n∆∞·ªõc
            thickness = 5 if label == "drowning" else 3
            cv2.rectangle(out, (x1, y1), (x2, y2), color, thickness)
            
            # Th√™m h√¨nh ch·ªØ nh·∫≠t ƒë·∫ßy m√†u ·ªü ph√≠a tr√™n cho n·ªÅn vƒÉn b·∫£n
            cv2.rectangle(out, (x1, y1 - 30), (x1 + 160, y1), color, -1)
            
            # Chuy·ªÉn ƒë·ªïi t√™n l·ªõp sang ti·∫øng Vi·ªát
            if label == "drowning":
                vn_label = "ƒêU·ªêI N∆Ø·ªöC"
            elif label == "swimming":
                vn_label = "B∆†I"
            elif label == "tread water":
                vn_label = "V√ôNG V·∫™Y"
            else:
                vn_label = label
                
            text = f"{vn_label}: {confidence:.2f}"
            
            # Th√™m vƒÉn b·∫£n
            font_scale = 0.7
            cv2.putText(out, text, (x1 + 5, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), 2)
        
        # Th√™m vƒÉn b·∫£n c·∫£nh b√°o n·∫øu ph√°t hi·ªán ƒëu·ªëi n∆∞·ªõc
        if is_drowning:
            height, width = out.shape[:2]
            warning_text = "PH√ÅT HI·ªÜN ƒêU·ªêI N∆Ø·ªöC!"
            text_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]
            text_x = (width - text_size[0]) // 2
            
            # Th√™m vƒÉn b·∫£n c·∫£nh b√°o ·ªü tr√™n c√πng
            cv2.putText(out, warning_text, (text_x, 70), 
                      cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
            
            # Th√™m ƒë∆∞·ªùng vi·ªÅn nh·∫•p nh√°y xung quanh khung h√¨nh
            border_thickness = int(3 + 2 * abs(np.sin(time.time() * 5)))
            cv2.rectangle(out, (5, 5), (width-5, height-5), (0, 0, 255), border_thickness)
        
        return out

def main():
    # Ti√™u ƒë·ªÅ v√† m√¥ t·∫£
    st.title("H·ªá th·ªëng ph√°t hi·ªán ƒëu·ªëi n∆∞·ªõc - DROWNING DETECTION")
    st.markdown("""
    **·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng YOLO ƒë·ªÉ ph√°t hi·ªán c√°c tr∆∞·ªùng h·ª£p ƒëu·ªëi n∆∞·ªõc trong video b∆°i l·ªôi.**
    
    T·∫£i l√™n video v√† h·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông ph√¢n t√≠ch ƒë·ªÉ ph√°t hi·ªán ng∆∞·ªùi ƒëu·ªëi n∆∞·ªõc.
    """)
    
    # Kh·ªüi t·∫°o ·ª©ng d·ª•ng
    app = DrowningDetectionApp()
    
    # Kh·ªüi t·∫°o session state
    if 'model_loaded' not in st.session_state:
        st.session_state.model_loaded = False
    if 'current_video' not in st.session_state:
        st.session_state.current_video = None
    if 'video_processed' not in st.session_state:
        st.session_state.video_processed = False
    
    # Sidebar cho l·ª±a ch·ªçn model v√† tham s·ªë
    with st.sidebar:
        st.header("C√†i ƒë·∫∑t")
        
        # L·ª±a ch·ªçn model
        model_name = st.selectbox(
            "Ch·ªçn Model",
            options=list(app.models.keys()),
            index=2  # Model 3 (best2.pt) l√† model t·ªët nh·∫•t
        )
        model_path = app.models[model_name]
        
        # Hi·ªÉn th·ªã phi√™n b·∫£n
        st.markdown("---")
        st.caption(f"PyTorch version: {torch.__version__}")
        st.caption(f"Ultralytics version: {ultralytics.__version__}")
        
        # T·ª± ƒë·ªông t·∫£i model n·∫øu ch∆∞a t·∫£i
        if not st.session_state.model_loaded:
            with st.spinner("ƒêang t·∫£i model..."):
                if app.load_model(model_path):
                    st.session_state.model_loaded = True
        
        # N√∫t t·∫£i model th·ªß c√¥ng
        if st.button("T·∫£i l·∫°i Model"):
            with st.spinner("ƒêang t·∫£i model..."):
                if app.load_model(model_path):
                    st.session_state.model_loaded = True
                    st.session_state.video_processed = False  # Reset tr·∫°ng th√°i x·ª≠ l√Ω
        
        st.divider()
        
        # C√°c tham s·ªë
        st.subheader("Tham s·ªë ph√°t hi·ªán")
        conf_threshold = st.slider(
            "Ng∆∞·ª°ng tin c·∫≠y (Confidence)",
            min_value=0.1,
            max_value=0.9,
            value=app.conf_threshold,
            step=0.05,
            help="Ng∆∞·ª°ng t·ªëi thi·ªÉu ƒë·ªÉ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng"
        )
        
        alert_conf = st.slider(
            "Ng∆∞·ª°ng c·∫£nh b√°o (Alert)",
            min_value=0.1,
            max_value=0.9,
            value=app.alert_conf,
            step=0.05,
            help="Ng∆∞·ª°ng tin c·∫≠y ƒë·ªÉ k√≠ch ho·∫°t c·∫£nh b√°o ƒëu·ªëi n∆∞·ªõc"
        )
        
        alert_time = st.slider(
            "Th·ªùi gian c·∫£nh b√°o (gi√¢y)",
            min_value=1.0,
            max_value=10.0,
            value=app.alert_time,
            step=0.5,
            help="Th·ªùi gian t·ªëi thi·ªÉu ph√°t hi·ªán ƒëu·ªëi n∆∞·ªõc li√™n t·ª•c tr∆∞·ªõc khi c·∫£nh b√°o"
        )
        
        # Thay ƒë·ªïi tham s·ªë reset tr·∫°ng th√°i ƒë√£ x·ª≠ l√Ω video
        if conf_threshold != app.conf_threshold or alert_conf != app.alert_conf or alert_time != app.alert_time:
            app.conf_threshold = conf_threshold
            app.alert_conf = alert_conf
            app.alert_time = alert_time
            st.session_state.video_processed = False
    
    # Khu v·ª±c n·ªôi dung ch√≠nh
    # T·∫£i l√™n video
    st.subheader("T·∫£i l√™n video")
    video_file = st.file_uploader("", type=["mp4", "avi", "mov", "mkv"])
    
    if video_file is not None:
        # Ki·ªÉm tra xem c√≥ ph·∫£i video m·ªõi kh√¥ng
        if st.session_state.current_video != video_file.name:
            st.session_state.current_video = video_file.name
            st.session_state.video_processed = False
        
        # Hi·ªÉn th·ªã th√¥ng tin file
        file_details = {"T√™n file": video_file.name, "Lo·∫°i file": video_file.type, "K√≠ch th∆∞·ªõc": f"{video_file.size / (1024*1024):.2f} MB"}
        st.write(file_details)
        
        # Xem tr∆∞·ªõc video
        st.video(video_file)
        
        # T·ª± ƒë·ªông x·ª≠ l√Ω n·∫øu ch∆∞a x·ª≠ l√Ω
        if not st.session_state.video_processed:
            if app.model is None:
                st.error("Model ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ƒë·ª£i model t·∫£i xong ho·∫∑c nh·∫•n 'T·∫£i l·∫°i Model'.")
            else:
                with st.spinner("ƒêang t·ª± ƒë·ªông x·ª≠ l√Ω video..."):
                    # C·∫ßn reset v·ªã tr√≠ c·ªßa file video
                    video_file.seek(0)
                    app.process_video(video_file, conf_threshold, alert_conf, alert_time)
                    st.session_state.video_processed = True
        
        # N√∫t x·ª≠ l√Ω l·∫°i
        if st.button("X·ª≠ l√Ω l·∫°i"):
            st.session_state.video_processed = False
            video_file.seek(0)  # Reset v·ªã tr√≠ file
            with st.spinner("ƒêang x·ª≠ l√Ω video..."):
                app.process_video(video_file, conf_threshold, alert_conf, alert_time)
                st.session_state.video_processed = True
    
    # Hi·ªÉn th·ªã ph·∫ßn h∆∞·ªõng d·∫´n
    with st.expander("H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"):
        st.markdown("""
        ### C√°ch s·ª≠ d·ª•ng:
        1. **Ch·ªçn model** t·ª´ thanh b√™n tr√°i (Model 3 - best2.pt l√† model t·ªët nh·∫•t)
        2. **ƒêi·ªÅu ch·ªânh c√°c tham s·ªë** ph√°t hi·ªán:
           - **Ng∆∞·ª°ng tin c·∫≠y**: ƒê·∫∑t th·∫•p (0.25) ƒë·ªÉ ph√°t hi·ªán nhi·ªÅu ƒë·ªëi t∆∞·ª£ng h∆°n, ƒë·∫∑t cao (0.5+) cho ƒë·ªô ch√≠nh x√°c cao h∆°n
           - **Ng∆∞·ª°ng c·∫£nh b√°o**: ƒê·∫∑t cao (0.65+) ƒë·ªÉ tr√°nh c·∫£nh b√°o gi·∫£
           - **Th·ªùi gian c·∫£nh b√°o**: Th·ªùi gian c·∫ßn ph√°t hi·ªán ƒëu·ªëi n∆∞·ªõc li√™n t·ª•c tr∆∞·ªõc khi c·∫£nh b√°o
        3. **T·∫£i l√™n video** ƒë·ªÉ ph√¢n t√≠ch
        4. H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω v√† hi·ªÉn th·ªã k·∫øt qu·∫£
        
        ### √ù nghƒ©a m√†u s·∫Øc:
        - **Xanh l√°**: Ng∆∞·ªùi ƒëang b∆°i b√¨nh th∆∞·ªùng
        - **V√†ng**: Ng∆∞·ªùi ƒëang v√πng v·∫´y/b∆°i t·∫°i ch·ªó
        - **ƒê·ªè**: Ng∆∞·ªùi ƒëang ƒëu·ªëi n∆∞·ªõc
        
        ### Khi c√≥ c·∫£nh b√°o:
        - Vi·ªÅn ƒë·ªè nh·∫•p nh√°y s·∫Ω xu·∫•t hi·ªán quanh khung h√¨nh
        - Th√¥ng b√°o "PH√ÅT HI·ªÜN ƒêU·ªêI N∆Ø·ªöC!" ƒë∆∞·ª£c hi·ªÉn th·ªã
        - H√¨nh ·∫£nh s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông l∆∞u
        """)
        
    # Footer
    st.markdown("---")
    st.caption("¬© H·ªá th·ªëng ph√°t hi·ªán ƒëu·ªëi n∆∞·ªõc - S·ª≠ d·ª•ng YOLOv8 cho ph√°t hi·ªán ƒëu·ªëi n∆∞·ªõc trong th·ªùi gian th·ª±c")

if __name__ == "__main__":
    main() 